# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KuvCh3Xy029txp6Hiwz2I4aQP0QwMmDS

#**Data Understanding**
"""

!pip install -q kaggle

from google.colab import files
files.upload()

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
import seaborn as sns
# %matplotlib inline

!mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download -d karkavelrajaj/amazon-sales-dataset

! mkdir amazon-sales-dataset

! unzip amazon-sales-dataset.zip -d amazon-sales-dataset

amazonSales = pd.read_csv('amazon-sales-dataset/amazon.csv')
amazonSales

"""#**Data Preparation**"""

amazonSales.info()

"""##**Data Cleaning**"""

def clean_and_convert(value):
    if value == '|':
        return None
    else:
        return float(value)

amazonSales['rating'] = amazonSales['rating'].apply(clean_and_convert)

print(amazonSales['rating'])
print(amazonSales['rating'].dtypes)

amazonSales.info()

amazonSales['rating'].describe()

amazonSales.isnull().sum()

all_amazonSales_clean = amazonSales.dropna()
all_amazonSales_clean

all_amazonSales_clean.isnull().sum()

amazonSales_category = all_amazonSales_clean.loc[:, ['product_id', 'product_name', 'category']]
amazonSales_category

amazonSales_category.isnull().sum()

"""**Mengurutkan product berdasarkan product_id kemudian memasukkannya ke dalam variabel fix_amazonSales_category**"""

fix_amazonSales_category = amazonSales_category.sort_values('product_id', ascending=True)
fix_amazonSales_category

"""**Mengecek berapa jumlah fix_amazonSales_category**"""

len(fix_amazonSales_category.product_id.unique())

"""**Mengecek kategori produk yang unik**"""

fix_amazonSales_category.category.unique()

"""**Membuat variabel preparation yang berisi dataframe fix_amazonSales_category kemudian diurutkan berdasarkan product_id**"""

preparation = fix_amazonSales_category
preparation.sort_values('product_id')

"""**Membuang data duplikat pada variabel preparation**"""

preparation = preparation.drop_duplicates('product_id')
preparation

"""**Mengkonversi data series menjadi dalam bentuk list**"""

product_id = preparation['product_id'].tolist()

product_name = preparation['product_name'].tolist()

category = preparation['category'].tolist()

print(len(product_id))
print(len(product_name))
print(len(category))

"""**Membuat dictionary untuk data product_id, product_name, dan category**"""

new_amazonSales_category = pd.DataFrame({
    'product_id': product_id,
    'product_name': product_name,
    'category': category
})
new_amazonSales_category

"""#**Model Development dengan Content Based Filtering**"""

data = new_amazonSales_category
data.sample(5)

"""**Inisialisasi TfidfVectorizer, Melakukan perhitungan idf pada data category, dan Mapping array dari fitur index integer ke fitur nama**"""

from sklearn.feature_extraction.text import TfidfVectorizer

tf = TfidfVectorizer()

tf.fit(data['category'])

tf.get_feature_names_out()

"""**Melakukan fit lalu ditransformasikan ke bentuk matrix dan Melihat ukuran matrix tfidf**"""

tfidf_matrix = tf.fit_transform(data['category'])

tfidf_matrix.shape

"""**Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()**"""

tfidf_matrix.todense()

"""**Membuat dataframe untuk melihat tf-idf matrix, Kolom diisi dengan kategori produk, dan Baris diisi dengan nama produk**"""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=data.product_name
).sample(22, axis=1).sample(10, axis=0)

"""**Menghitung cosine similarity pada matrix tf-idf**"""

from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""**Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama produk dan Melihat similarity matrix pada setiap produk**"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=data['product_name'], columns=data['product_name'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

def product_recommendations(product_name, similarity_data=cosine_sim_df, items=data[['product_name', 'category']], k=5):
    """
    Rekomendasi Product berdasarkan kemiripan dataframe

    Parameter:
    ---
    product_name : tipe data string (str)
                Nama produk (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan produk sebagai
                      indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---


    Pada index ini, kita mengambil k dengan nilai similarity terbesar
    pada index matrix yang diberikan (i).
    """

    index = similarity_data.loc[:,product_name].to_numpy().argpartition(
        range(-1, -k, -1))

    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    closest = closest.drop(product_name, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

data[data.product_name.eq('Wayona Nylon Braided USB to Lightning Fast Charging and Data Sync Cable Compatible for iPhone 13, 12,11, X, 8, 7, 6, 5, iPad Air, Pro, Mini (3 FT Pack of 1, Grey)')]

"""**Mendapatkan rekomendasi produk yang mirip dengan produk yang dimasukkan pada product_recommendations.**"""

product_recommendations('Wayona Nylon Braided USB to Lightning Fast Charging and Data Sync Cable Compatible for iPhone 13, 12,11, X, 8, 7, 6, 5, iPad Air, Pro, Mini (3 FT Pack of 1, Grey)')

"""#**Model Development dengan Collaborative Filtering**

#**Data Understanding**
"""

# Import library
import pandas as pd
import numpy as np
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

df = all_amazonSales_clean.loc[:, ['product_id', 'product_name', 'rating', 'user_id']]
df

"""#**Data Preparation**"""

# Mengubah user_id menjadi list tanpa nilai yang sama
user_ids = df['user_id'].unique().tolist()
print('list user_id: ', user_ids)

# Melakukan encoding user_id
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke user_id
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke user_id: ', user_encoded_to_user)

# Mengubah product_id menjadi list tanpa nilai yang sama
product_ids = df['product_id'].unique().tolist()

# Melakukan proses encoding product_id
product_to_product_encoded = {x: i for i, x in enumerate(product_ids)}

# Melakukan proses encoding angka ke product_id
product_encoded_to_product = {i: x for i, x in enumerate(product_ids)}

# Mapping userID ke dataframe user
df['user'] = df['user_id'].map(user_to_user_encoded)

# Mapping placeID ke dataframe produk
df['product'] = df['product_id'].map(product_to_product_encoded)

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah product
num_products = len(product_encoded_to_product)
print(num_products)

# Mengubah atau memastikkan kalau rating menjadi nilai float
df['rating'] = df['rating'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(df['rating'])

# Nilai maksimal rating
max_rating = max(df['rating'])

print('Number of User: {}, Number of Product: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_products, min_rating, max_rating
))

"""#**Membagi Data untuk Training dan Validasi**"""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

# Membuat variabel x untuk mencocokkan data user dan produk menjadi satu value
x = df[['user', 'product']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""#**Proses Training**"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_products, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_products = num_products
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.products_embedding = layers.Embedding( # layer embeddings product
        num_products,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.products_bias = layers.Embedding(num_products, 1) # layer embedding product bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    products_vector = self.products_embedding(inputs[:, 1]) # memanggil layer embedding 3
    products_bias = self.products_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_product = tf.tensordot(user_vector, products_vector, 2)

    x = dot_user_product + user_bias + products_bias

    return tf.nn.sigmoid(x) # activation sigmoid

"""**proses compile terhadap model. serta menggunakan matrix evaluasi RMSE**"""

model = RecommenderNet(num_users, num_products, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Memulai training

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""#**Visualisasi Metrik**"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""#**Mendapatkan Rekomendasi Produk**"""

products_df = new_amazonSales_category
df = all_amazonSales_clean.loc[:, ['product_id', 'product_name', 'rating', 'user_id']]

# Mengambil sample user
user_id = df.user_id.sample(1).iloc[0]
products_experienced_by_user = df[df.user_id == user_id]

products_not_experienced = products_df[~products_df['product_id'].isin(products_experienced_by_user.product_id.values)]['product_id']
products_not_experienced = list(
    set(products_not_experienced)
    .intersection(set(product_to_product_encoded.keys()))
)

products_not_experienced = [[product_to_product_encoded.get(x)] for x in products_not_experienced]
user_encoder = user_to_user_encoded.get(user_id)
user_product_array = np.hstack(
    ([[user_encoder]] * len(products_not_experienced), products_not_experienced)
)

ratings = model.predict(user_product_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_products_ids = [
    product_encoded_to_product.get(products_not_experienced[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Products with high ratings from user')
print('----' * 8)

top_products_user = (
    products_experienced_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .product_id.values
)

products_df_rows = products_df[products_df['product_id'].isin(top_products_user)]
for row in products_df_rows.itertuples():
    print(row.product_name, ':', row.category)

print('----' * 8)
print('Top 10 Products recommendation')
print('----' * 8)

recommended_products = products_df[products_df['product_id'].isin(recommended_products_ids)]
for row in recommended_products.itertuples():
    print(row.product_name, ':', row.category)

"""**MSE**"""

from sklearn.metrics import mean_squared_error
print("MSE dari pada data train = ", mean_squared_error(y_true=y_train, y_pred=model.predict(x_train))/1e3)
print("MSE dari pada data validation = ", mean_squared_error(y_true=y_val, y_pred=model.predict(x_val))/1e3)